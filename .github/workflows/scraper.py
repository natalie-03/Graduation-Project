import requests
import pandas as pd
import time
import random
import os
from datetime import datetime

# --- è¨­å®šå€ ---
BOARDS = {
    "travel": "æ—…éŠ.csv",
    "food": "ç¾é£Ÿ.csv",
    "job": "å·¥ä½œ.csv",
    "graduate_school": "ç ”ç©¶æ‰€.csv",
    "exam": "è€ƒè©¦.csv"
}

# è¨­å®šæ¯å€‹çœ‹æ¿è¦çˆ¬å¹¾ç¯‡
# API é€Ÿåº¦å¾ˆå¿«ï¼Œä½†å»ºè­°å–®æ¬¡ä¸è¦è¶…é 500ï¼Œä»¥å…è§¸ç™¼ Rate Limit (429)
TARGET_PER_BOARD = 400 
OUTPUT_DIR = "csv"

# å½è£æˆä¸€èˆ¬ç€è¦½å™¨çš„æ¨™é ­
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Referer": "https://www.dcard.tw/",
    "Accept": "application/json"
}

def get_posts(board, limit=30, before=None):
    """å‘¼å« Dcard API å–å¾—æ–‡ç« åˆ—è¡¨"""
    # Dcard API ç¶²å€
    url = f"https://www.dcard.tw/service/api/v2/forums/{board}/posts?popular=false&limit={limit}"
    if before:
        url += f"&before={before}"
    
    try:
        resp = requests.get(url, headers=HEADERS, timeout=10)
        if resp.status_code == 200:
            return resp.json()
        elif resp.status_code == 429:
            print("âš ï¸ API è«‹æ±‚éæ–¼é »ç¹ (429)ï¼Œä¼‘æ¯ 10 ç§’...")
            time.sleep(10)
            return []
        else:
            print(f"âš ï¸ API éŒ¯èª¤ {resp.status_code}: {url}")
            return []
    except Exception as e:
        print(f"âŒ é€£ç·šå¤±æ•—: {e}")
        return []

def crawl_board_api(board, filename):
    csv_path = os.path.join(OUTPUT_DIR, filename)
    print(f"ğŸš€ [API] é–‹å§‹çˆ¬å–çœ‹æ¿ï¼š{board}")
    
    all_posts = []
    existing_ids = set()

    # 1. è®€å–èˆŠè³‡æ–™ï¼Œé¿å…é‡è¤‡ (æ ¹æ“šæ–‡ç«  ID)
    if os.path.exists(csv_path):
        try:
            old_df = pd.read_csv(csv_path)
            if "id" in old_df.columns:
                existing_ids = set(old_df["id"].astype(str).unique())
            print(f"   ğŸ“– å·²è®€å–ç¾æœ‰è³‡æ–™ {len(existing_ids)} ç­†")
        except Exception as e:
            print(f"   âš ï¸ è®€å–èˆŠæª”å¤±æ•—ï¼Œå°‡å»ºç«‹æ–°æª”: {e}")

    last_id = None
    collected_count = 0
    retry_count = 0

    while collected_count < TARGET_PER_BOARD:
        # æ¯æ¬¡æŠ“ 30 ç­†
        batch = get_posts(board, limit=30, before=last_id)
        
        if not batch:
            retry_count += 1
            if retry_count > 3:
                print("   âš ï¸ é€£çºŒå¤±æ•—ï¼Œåœæ­¢çˆ¬å–æœ¬çœ‹æ¿")
                break
            time.sleep(2)
            continue
            
        new_items = []
        for post in batch:
            pid = str(post.get("id"))
            
            # ç•¥éå·²å­˜åœ¨æˆ–ç½®é ‚å…¬å‘Š
            if pid in existing_ids or post.get("pinned"):
                continue
                
            # æ•´ç†è³‡æ–™
            item = {
                "id": pid,
                "title": post.get("title"),
                "excerpt": post.get("excerpt", ""),
                "link": f"https://www.dcard.tw/f/{board}/p/{pid}",
                "likeCount": post.get("likeCount", 0),
                "commentCount": post.get("commentCount", 0),
                "createdAt": post.get("createdAt"),
                "updatedAt": post.get("updatedAt"),
                "gender": post.get("gender"),
                "school": post.get("school"),
                "topics": ",".join(post.get("topics", []))
            }
            new_items.append(item)
            existing_ids.add(pid)
            
            # æ›´æ–° last_id ç”¨æ–¼ç¿»é 
            last_id = post.get("id")

        if new_items:
            all_posts.extend(new_items)
            collected_count += len(new_items)
            print(f"   âœ… å–å¾— {len(new_items)} ç­†æ–°æ–‡ç«  (ç›®å‰ç´¯ç©: {collected_count})")
            retry_count = 0 # é‡ç½®é‡è©¦è¨ˆæ•¸
        else:
            print("   â„¹ï¸ æœ¬é ç„¡æ–°æ–‡ç«  (å¯èƒ½éƒ½é‡è¤‡äº†)")
            if batch:
                last_id = batch[-1].get("id")

        # éš¨æ©Ÿä¼‘æ¯
        time.sleep(random.uniform(1, 2))

    # å­˜æª”
    if all_posts:
        df = pd.DataFrame(all_posts)
        header = not os.path.exists(csv_path)
        df.to_csv(csv_path, mode='a', header=header, index=False, encoding='utf-8-sig')
        print(f"   ğŸ’¾ å·²å„²å­˜ {len(all_posts)} ç­†è³‡æ–™è‡³ {csv_path}")
    else:
        print("   ğŸ’¤ æœ¬æ¬¡ç„¡æ–°å¢è³‡æ–™")

def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    for board, filename in BOARDS.items():
        crawl_board_api(board, filename)
        time.sleep(3)

if __name__ == "__main__":
    main()
