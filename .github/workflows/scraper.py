import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
import pandas as pd
import random
import os
import gc
import time

BOARDS = {
    "travel": "æ—…éŠ.csv",
    #"food": "ç¾é£Ÿ.csv",
    #"job": "å·¥ä½œ.csv",
    #"graduate_school": "ç ”ç©¶æ‰€.csv",
    #"exam": "è€ƒè©¦.csv"
}

def init_driver():
    """åˆå§‹åŒ–é©…å‹•ç¨‹å¼ - å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨"""
    opts = uc.ChromeOptions()
    opts.add_argument("--disable-blink-features=AutomationControlled")
    opts.add_argument("--disable-notifications")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--memory-pressure-off")
    opts.add_experimental_option("prefs", {"profile.default_content_setting_values.notifications": 2})
    
    try:
        driver = uc.Chrome(options=opts, version_main=142)
        driver.set_page_load_timeout(30)
        return driver
    except Exception as e:
        print(f"é©…å‹•ç¨‹å¼åˆå§‹åŒ–å¤±æ•—: {e}")
        return None

def collect_links(driver, board_url, max_scroll=200):
    """æ”¶é›†æ–‡ç« é€£çµ - å„ªåŒ–æ•ˆèƒ½ç‰ˆæœ¬"""
    print(f"é–‹å§‹æ”¶é›† {board_url} çš„æ–‡ç« é€£çµ...")
    
    try:
        driver.get(board_url)
        time.sleep(1)  # åˆå§‹è¼‰å…¥ç­‰å¾…
        
        links = set()
        last_count = 0
        no_new_count = 0
        
        for i in range(max_scroll):
            # æ»¾å‹•é é¢
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(random.uniform(1, 1.5))  # æ»¾å‹•é–“éš”
            
            # æ”¶é›†é€£çµ
            try:
                articles = WebDriverWait(driver, 5).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a[href*="/p/"]'))
                )
                
                for article in articles[-20:]:  # åªè™•ç†æœ€è¿‘çš„æ–‡ç« é¿å…é‡è¤‡
                    try:
                        href = article.get_attribute("href")
                        if href and "/p/" in href and href not in links:
                            links.add(href)
                    except:
                        continue
            except TimeoutException:
                print("  æ‰¾ä¸åˆ°æ–‡ç« å…ƒç´ ï¼Œç¹¼çºŒæ»¾å‹•...")
                continue
            
            # æª¢æŸ¥é€²åº¦
            current_count = len(links)
            if current_count == last_count:
                no_new_count += 1
                if no_new_count >= 20:  # é€£çºŒ20æ¬¡ç„¡æ–°é€£çµå°±åœæ­¢
                    print(f"  å·²ç„¡æ–°æ–‡ç« ï¼Œåœæ­¢æ»¾å‹•ã€‚å…±æ”¶é›† {len(links)} ç¯‡")
                    break
            else:
                no_new_count = 0
                last_count = current_count
            
            # é€²åº¦é¡¯ç¤º
            if (i + 1) % 20 == 0:
                print(f"  å·²æ»¾å‹• {i+1} æ¬¡ï¼Œæ”¶é›† {len(links)} ç¯‡æ–‡ç« ")
                
            # è¨˜æ†¶é«”é‡‹æ”¾
            if (i + 1) % 50 == 0:
                driver.execute_script("window.stop();")
                time.sleep(1)
                
        return list(links)[:10000]  # é™åˆ¶æœ€å¤§æ–‡ç« æ•¸é¿å…è¨˜æ†¶é«”ä¸è¶³
    
    except Exception as e:
        print(f"æ”¶é›†é€£çµæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def parse_article(driver, url):
    """è§£æå–®ç¯‡æ–‡ç«  - å¢å¼·ç©©å®šæ€§å’ŒéŒ¯èª¤è™•ç†"""
    try:
        driver.get(url)
        time.sleep(random.uniform(1, 2))
        
        # ä½¿ç”¨æ›´ç©©å®šçš„ç­‰å¾…æ–¹å¼
        title = "ç„¡æ¨™é¡Œ"
        content = ""
        comments = ""
        
        try:
            title_elem = WebDriverWait(driver, 5).until(
                EC.presence_of_element_located((By.TAG_NAME, "h1"))
            )
            title = title_elem.text.strip()
        except:
            try:
                title_elem = driver.find_element(By.TAG_NAME, "h1")
                title = title_elem.text.strip()
            except:
                pass
        
        try:
            content_elem = driver.find_element(By.TAG_NAME, "article")
            content = content_elem.text.strip()
        except:
            pass
        
        try:
            comment_elems = driver.find_elements(By.CSS_SELECTOR, '[data-testid="comment"], .comment, .Post_comments_1_Nhv')
            comments = " || ".join([cmt.text.strip() for cmt in comment_elems[:10] if cmt.text.strip()])  # é™åˆ¶è©•è«–æ•¸é‡
        except:
            pass
        
        return [title, content, comments, url]
        
    except Exception as e:
        print(f"è§£ææ–‡ç« å¤±æ•— {url}: {e}")
        return ["è§£æå¤±æ•—", "", "", url]

def save_batch_data(board_name, batch_data, batch_num):
    """æ‰¹æ¬¡å„²å­˜è³‡æ–™ä¸¦é‡‹æ”¾è¨˜æ†¶é«”"""
    if not batch_data:
        return
    
    csv_name = BOARDS[board_name]
    df = pd.DataFrame(batch_data, columns=["title", "content", "comments", "link"])
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¾†æ±ºå®šæ˜¯å¦å¯«å…¥æ¨™é ­
    file_exists = os.path.exists(csv_name)
    
    try:
        df.to_csv(csv_name, mode='a', header=not file_exists, index=False, encoding='utf-8-sig')
        print(f"  æ‰¹æ¬¡ {batch_num} å·²å„²å­˜ {len(batch_data)} ç¯‡æ–‡ç« åˆ° {csv_name}")
    except Exception as e:
        print(f"å„²å­˜å¤±æ•—: {e}")
    
    # é‡‹æ”¾è¨˜æ†¶é«”
    del df
    gc.collect()

def process_board(driver, board_name):
    """è™•ç†å–®å€‹çœ‹æ¿"""
    print(f"\né–‹å§‹çˆ¬å– {board_name} ç‰ˆ...")
    
    csv_name = BOARDS[board_name]
    

    
    # æ”¶é›†é€£çµ
    url = f"https://www.dcard.tw/f/{board_name}"
    links = collect_links(driver, url)
    
    if not links:
        print(f"âŒ ç„¡æ³•æ”¶é›†åˆ° {board_name} çš„æ–‡ç« é€£çµ")
        return
    
    print(f"æ‰¾åˆ° {len(links)} ç¯‡æ–‡ç« ï¼Œé–‹å§‹è§£æ...")
    
    # æ‰¹æ¬¡è™•ç†æ–‡ç« 
    batch_size = 10  # æ¸›å°æ‰¹æ¬¡å¤§å°ä»¥ç¯€çœè¨˜æ†¶é«”
    batch_data = []
    batch_num = 1
    
    for i, link in enumerate(links, 1):
        try:
            article_data = parse_article(driver, link)
            batch_data.append(article_data)
            
            print(f"  å·²è§£æ {i}/{len(links)}: {article_data[0][:30]}...")
            
            # éš¨æ©Ÿå»¶é²
            time.sleep(random.uniform(1, 3))
            
            # æ‰¹æ¬¡å„²å­˜
            if len(batch_data) >= batch_size:
                save_batch_data(board_name, batch_data, batch_num)
                batch_data = []
                batch_num += 1
                
                # ä¼‘æ¯ä¸€ä¸‹é¿å…è¢«å°
                time.sleep(2)
                
        except Exception as e:
            print(f"è™•ç†æ–‡ç«  {link} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
    
    # å„²å­˜æœ€å¾Œä¸€æ‰¹è³‡æ–™
    if batch_data:
        save_batch_data(board_name, batch_data, batch_num)
    
    print(f"âœ… {board_name} ç‰ˆå®Œæˆï¼Œå…±è™•ç† {len(links)} ç¯‡æ–‡ç« ")

def main():
    """ä¸»ç¨‹å¼ - å„ªåŒ–è¨˜æ†¶é«”ç®¡ç†"""
    driver = init_driver()
    if not driver:
        print("âŒ ç„¡æ³•å•Ÿå‹•ç€è¦½å™¨ï¼Œç¨‹å¼çµæŸ")
        return
    
    try:
        for board_name in BOARDS.keys():
            process_board(driver, board_name)
            
            # æ¯å€‹çœ‹æ¿å®Œæˆå¾Œä¼‘æ¯ä¸€ä¸‹
            time.sleep(1)
            
        print("\nğŸ‰ æ‰€æœ‰çœ‹æ¿çˆ¬å–å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ä½¿ç”¨è€…ä¸­æ–·ç¨‹å¼")
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {e}")
    finally:
        if driver:
            driver.quit()
            print("ğŸ”š ç€è¦½å™¨å·²é—œé–‰")
        
        # å¼·åˆ¶åƒåœ¾å›æ”¶
        gc.collect()

if __name__ == "__main__":
    main()
