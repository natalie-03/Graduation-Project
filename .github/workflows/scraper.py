import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pandas as pd
import time
import random
import os

# -----------------------------
BOARDS = {
    "travel": "æ—…éŠ.csv",
    "food": "ç¾é£Ÿ.csv", 
    "job": "å·¥ä½œ.csv",
    "graduate_school": "ç ”ç©¶æ‰€.csv",
    "exam": "è€ƒè©¦.csv"
}

OUTPUT_DIR = "csv"
TARGET_COUNT = 30  # é€²ä¸€æ­¥é™ä½ç›®æ¨™æ•¸é‡
BATCH_SIZE = 3
# -----------------------------

def get_driver():
    options = uc.ChromeOptions()
    
    # å˜—è©¦ä¸ä½¿ç”¨ headless æ¨¡å¼çœ‹çœ‹
    # options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    
    # ä½¿ç”¨æ›´å¸¸è¦‹çš„ user agent
    options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    options.add_argument("--window-size=1920,1080")
    
    print("æ­£åœ¨å•Ÿå‹• Chrome...")
    try:
        driver = uc.Chrome(
            options=options,
            version_main=None
        )
        # ç§»é™¤ automation æ¨™èªŒ
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        driver.execute_cdp_cmd('Network.setUserAgentOverride', {
            "userAgent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        return driver
    except Exception as e:
        print(f"å•Ÿå‹• Chrome å¤±æ•—: {e}")
        raise

def save_csv(new_rows, filepath):
    if not new_rows:
        print("âš ï¸ ç„¡æ–°è³‡æ–™å¯å„²å­˜")
        return
        
    df = pd.DataFrame(new_rows)
    header = not os.path.exists(filepath)
    df.to_csv(filepath, mode='a', header=header, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ å·²å„²å­˜ {len(new_rows)} ç­†è³‡æ–™åˆ° {filepath}")

def crawl_board(driver, board, filename):
    csv_path = os.path.join(OUTPUT_DIR, filename)
    url = f"https://www.dcard.tw/f/{board}"
    print(f"ğŸš€ é–‹å§‹çˆ¬å–ï¼š{board} ({url})")

    data = []
    collected_urls = set()

    # è®€å–èˆŠè³‡æ–™é¿å…é‡è¤‡
    if os.path.exists(csv_path):
        try:
            old_df = pd.read_csv(csv_path)
            if "link" in old_df.columns:
                collected_urls = set(old_df["link"].dropna().unique())
            print(f"  å·²è®€å–ç¾æœ‰è³‡æ–™ {len(collected_urls)} ç­†")
        except Exception as e:
            print(f"  è®€å–èˆŠè³‡æ–™å¤±æ•—: {e}")

    try:
        print(f"  è¼‰å…¥é é¢...")
        driver.get(url)
        # ç­‰å¾…æ›´é•·æ™‚é–“è®“é é¢åŠ è¼‰
        time.sleep(5)
        
        # æª¢æŸ¥é é¢æ¨™é¡Œç¢ºèªè¼‰å…¥æˆåŠŸ
        print(f"  é é¢æ¨™é¡Œ: {driver.title}")
        
    except Exception as e:
        print(f"âŒ ç„¡æ³•è¼‰å…¥é é¢ {url}: {e}")
        return

    # å˜—è©¦å¤šç¨®æ–¹æ³•å°‹æ‰¾æ–‡ç« é€£çµ
    print("  å°‹æ‰¾æ–‡ç« é€£çµ...")
    
    # æ–¹æ³•1: å˜—è©¦ä¸åŒçš„é¸æ“‡å™¨
    selectors = [
        'a[href*="/p/"]',
        'article a',
        '.sc-37c4a7e2 a',  # Dcard çš„å¯èƒ½é¡å
        'h2 a',
        '[data-testid="title-anchor"]',
        'a[class*="Title"]',
        'a[class*="title"]',
        'a[class*="Post"]'
    ]
    
    all_links = []
    
    for selector in selectors:
        try:
            elements = driver.find_elements(By.CSS_SELECTOR, selector)
            for elem in elements:
                try:
                    href = elem.get_attribute('href')
                    if href and '/p/' in href and href not in all_links:
                        all_links.append(href)
                        print(f"    æ‰¾åˆ°é€£çµ: {href[:80]}...")
                except:
                    continue
            if all_links:
                print(f"  ä½¿ç”¨é¸æ“‡å™¨ '{selector}' æ‰¾åˆ° {len(elements)} å€‹å…ƒç´ ï¼Œ{len(all_links)} å€‹å”¯ä¸€é€£çµ")
                break
        except Exception as e:
            print(f"  é¸æ“‡å™¨ '{selector}' å¤±æ•—: {e}")
    
    # æ–¹æ³•2: å¦‚æœä¸Šé¢æ²’æ‰¾åˆ°ï¼Œå˜—è©¦é€šé XPath
    if not all_links:
        print("  å˜—è©¦ XPath å°‹æ‰¾...")
        xpaths = [
            "//a[contains(@href, '/p/')]",
            "//article//a",
            "//h2//a",
            "//a[contains(@class, 'title')]"
        ]
        
        for xpath in xpaths:
            try:
                elements = driver.find_elements(By.XPATH, xpath)
                for elem in elements:
                    try:
                        href = elem.get_attribute('href')
                        if href and '/p/' in href and href not in all_links:
                            all_links.append(href)
                    except:
                        continue
                if all_links:
                    print(f"  ä½¿ç”¨ XPath '{xpath}' æ‰¾åˆ° {len(all_links)} å€‹é€£çµ")
                    break
            except Exception as e:
                print(f"  XPath '{xpath}' å¤±æ•—: {e}")
    
    # æ–¹æ³•3: ç²å–é é¢æ‰€æœ‰é€£çµç„¶å¾Œéæ¿¾
    if not all_links:
        print("  ç²å–æ‰€æœ‰é€£çµé€²è¡Œéæ¿¾...")
        try:
            all_anchors = driver.find_elements(By.TAG_NAME, "a")
            for anchor in all_anchors:
                try:
                    href = anchor.get_attribute('href')
                    if href and '/p/' in href and href not in all_links:
                        all_links.append(href)
                except:
                    continue
            print(f"  å¾æ‰€æœ‰é€£çµä¸­éæ¿¾å‡º {len(all_links)} å€‹æ–‡ç« é€£çµ")
        except Exception as e:
            print(f"  ç²å–æ‰€æœ‰é€£çµå¤±æ•—: {e}")
    
    # å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°é€£çµï¼Œä¿å­˜é é¢æºç¢¼ç”¨æ–¼èª¿è©¦
    if not all_links:
        print("âŒ ç„¡æ³•æ‰¾åˆ°ä»»ä½•æ–‡ç« é€£çµ")
        debug_file = f"debug_{board}.html"
        try:
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write(driver.page_source)
            print(f"  å·²ä¿å­˜é é¢æºç¢¼åˆ° {debug_file} ç”¨æ–¼èª¿è©¦")
        except:
            print("  ç„¡æ³•ä¿å­˜èª¿è©¦æ–‡ä»¶")
        return
    
    # éæ¿¾æ‰é‡è¤‡çš„é€£çµ
    new_links = [link for link in all_links if link not in collected_urls][:TARGET_COUNT]
    
    for link in new_links:
        data.append({
            "title": "å¾…è§£æ", 
            "link": link,
            "content": "",
            "comments": ""
        })
    
    print(f"  ğŸ“Š æ‰¾åˆ° {len(new_links)} ç¯‡æ–°æ–‡ç« ")

    # çˆ¬å–æ–‡ç« å…§æ–‡
    results = []
    for i, item in enumerate(data):
        try:
            print(f"  æ­£åœ¨è™•ç†ç¬¬ {i+1}/{len(data)} ç¯‡æ–‡ç« ...")
            
            driver.get(item['link'])
            time.sleep(random.uniform(2, 3))
            
            # ç²å–æ¨™é¡Œ
            title = "ç„¡æ¨™é¡Œ"
            title_selectors = [
                "h1",
                "h2",
                ".sc-1963a7b-0 h1",
                "header h1",
                "title"
            ]
            
            for selector in title_selectors:
                try:
                    title_elem = driver.find_element(By.CSS_SELECTOR, selector)
                    title_text = title_elem.text.strip()
                    if title_text:
                        title = title_text
                        break
                except:
                    continue
            
            item['title'] = title
            
            # ç²å–å…§å®¹
            content = "ç„¡æ³•è®€å–å…§æ–‡"
            content_selectors = [
                "article",
                ".sc-7f6b7c1c-0",
                ".phqpq",
                "[data-testid='comment-content']",
                "div[class*='content']",
                "main"
            ]
            
            for selector in content_selectors:
                try:
                    content_elems = driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in content_elems:
                        text = elem.text.strip()
                        if text and len(text) > 10:
                            content = text
                            break
                    if content != "ç„¡æ³•è®€å–å…§æ–‡":
                        break
                except:
                    continue
            
            item['content'] = content
            
            # ç²å–è©•è«–
            comments = []
            comment_selectors = [
                "[data-testid='comment']",
                "[class*='comment']",
                ".sc-1963a7b-0"
            ]
            
            for selector in comment_selectors:
                try:
                    comment_elems = driver.find_elements(By.CSS_SELECTOR, selector)
                    for comment in comment_elems[:5]:  # åªå–å‰5æ¢è©•è«–
                        try:
                            comment_text = comment.text.strip()
                            if comment_text and len(comment_text) > 5:
                                comments.append(comment_text.replace("\n", " "))
                        except:
                            continue
                    if comments:
                        break
                except:
                    continue
            
            item['comments'] = " || ".join(comments) if comments else "ç„¡è©•è«–"
            
            results.append(item)
            print(f"  âœ… å®Œæˆ: {title[:30]}...")
            
            # æ‰¹æ¬¡å„²å­˜
            if len(results) >= BATCH_SIZE:
                save_csv(results, csv_path)
                results = []
                
        except Exception as e:
            print(f"  âŒ è™•ç†æ–‡ç« æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue

    # å„²å­˜å‰©é¤˜è³‡æ–™
    if results:
        save_csv(results, csv_path)
        
    print(f"âœ… {board} çœ‹æ¿çˆ¬å–å®Œæˆï¼Œå…±è™•ç† {len(data)} ç¯‡æ–‡ç« ")

def main():
    print("ğŸ¯ Dcard çˆ¬èŸ²é–‹å§‹åŸ·è¡Œ")
    
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"ğŸ“ å·²å»ºç«‹è³‡æ–™å¤¾: {OUTPUT_DIR}")

    driver = None
    try:
        driver = get_driver()
        
        # å…ˆæ¸¬è©¦ä¸€å€‹çœ‹æ¿
        board, filename = list(BOARDS.items())[0]
        print(f"\n{'='*50}")
        crawl_board(driver, board, filename)
        print(f"{'='*50}\n")
            
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")
    finally:
        if driver:
            print("ğŸ”„ é—œé–‰ç€è¦½å™¨...")
            driver.quit()
            
    print("ğŸ‰ çˆ¬å–å®Œæˆï¼")

if __name__ == "__main__":
    main()
